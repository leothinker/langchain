{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///Chinook.db\")\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8489c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"azure_openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(f\"{tool.name}: {tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Annotated, Any, List\n",
    "from uuid import uuid4\n",
    "\n",
    "import pandas as pd\n",
    "from langgraph.graph.message import MessagesState\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Artifact(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: str(uuid4()))\n",
    "\n",
    "\n",
    "class TableArtifact(Artifact):\n",
    "    type: str = \"table\"\n",
    "    query: str | None\n",
    "    result: Any | None\n",
    "\n",
    "\n",
    "class ChartArtifact(Artifact):\n",
    "    type: str = \"chart\"\n",
    "    query: str | None\n",
    "    options: Any | None\n",
    "    vis_script: str | None\n",
    "\n",
    "\n",
    "class TreeState(MessagesState):\n",
    "    # The unique ID\n",
    "    id: uuid.UUID\n",
    "    # The height of the current node\n",
    "    height: int\n",
    "    # The focused sub-problem\n",
    "    focused_problem: str\n",
    "    # The maximum initial height for expanding\n",
    "    max_height: int | None\n",
    "    # Reason of associating this focused_problem\n",
    "    # reason_of_associating: Optional[str]\n",
    "    # Original problem that trigerred this problem\n",
    "    original_problem: str | None\n",
    "    # Child list\n",
    "    child_list: List[\"TreeState\"] | None\n",
    "    # Responsd to this node as leaf\n",
    "    respond: str | None\n",
    "    # Visualization info about this node\n",
    "    artifact: Annotated[TableArtifact, ChartArtifact] | None\n",
    "    # Type of Visualization\n",
    "    artifact_type: str | None\n",
    "    # Node to be expanded\n",
    "    expanded_id: uuid.UUID | None\n",
    "    # Questions asked previously\n",
    "    prev_questions: List[str] | None\n",
    "    # Regenerate time record, 0 means no need to regenerate\n",
    "    regenerate_times: int | None\n",
    "    # num of subproblems need to generate\n",
    "    max_subproblems: int | None\n",
    "    # tables in the dataset\n",
    "    data_tables: str | None\n",
    "    # schema of data tables\n",
    "    data_schemas: dict | None\n",
    "    # first level subproblems number\n",
    "    first_level_subproblems: int | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28759232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Tuple, Type\n",
    "\n",
    "from langchain_community.tools.sql_database.prompt import QUERY_CHECKER\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import BaseTool\n",
    "from pydantic import BaseModel, ConfigDict, Field, model_validator\n",
    "\n",
    "\n",
    "class BaseSQLDatabaseTool(BaseModel):\n",
    "    \"\"\"Base tool for interacting with a SQL database.\"\"\"\n",
    "\n",
    "    db: SQLDatabase = Field(exclude=True)\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True,\n",
    "    )\n",
    "\n",
    "\n",
    "class _QuerySQLDataBaseToolInput(BaseModel):\n",
    "    query: str = Field(..., description=\"A detailed and correct SQL query.\")\n",
    "\n",
    "\n",
    "class QuerySQLDataBaseTool(BaseSQLDatabaseTool, BaseTool):  # type: ignore[override, override]\n",
    "    \"\"\"Tool for querying a SQL database.\"\"\"\n",
    "\n",
    "    name: str = \"sql_db_query\"\n",
    "    description: str = \"\"\"\n",
    "    Execute a SQL query against the database and get back the result.\n",
    "    If the query is not correct, an error message will be returned.\n",
    "    Empty result is regarded correct.\n",
    "    \"\"\"\n",
    "    args_schema: Type[BaseModel] = _QuerySQLDataBaseToolInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: CallbackManagerForToolRun | None = None,\n",
    "    ) -> Tuple[str, Any]:\n",
    "        \"\"\"Execute the query, return the results or an error message.\"\"\"\n",
    "        result = self.db.run(query, include_columns=True)\n",
    "        return str(result), result\n",
    "\n",
    "\n",
    "class _InfoSQLDatabaseToolInput(BaseModel):\n",
    "    table_names: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"A comma-separated list of the table names for which to return the schema. \"\n",
    "            \"Example input: 'table1, table2, table3'\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "class InfoSQLDatabaseTool(BaseSQLDatabaseTool, BaseTool):  # type: ignore[override, override]\n",
    "    \"\"\"Tool for getting metadata about a SQL database.\"\"\"\n",
    "\n",
    "    name: str = \"sql_db_schema\"\n",
    "    description: str = \"Get the schema and sample rows for the specified SQL tables.\"\n",
    "    args_schema: Type[BaseModel] = _InfoSQLDatabaseToolInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        table_names: str,\n",
    "        run_manager: CallbackManagerForToolRun | None = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Get the schema for tables in a comma-separated list.\"\"\"\n",
    "        return self.db.get_table_info_no_throw([t.strip() for t in table_names.split(\",\")])\n",
    "\n",
    "\n",
    "class _ListSQLDataBaseToolInput(BaseModel):\n",
    "    tool_input: str = Field(\"\", description=\"An empty string\")\n",
    "\n",
    "\n",
    "class ListSQLDatabaseTool(BaseSQLDatabaseTool, BaseTool):  # type: ignore[override, override]\n",
    "    \"\"\"Tool for getting tables names.\"\"\"\n",
    "\n",
    "    name: str = \"sql_db_list_tables\"\n",
    "    description: str = (\n",
    "        \"Input is an empty string, output is a comma-separated list of tables in the database.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = _ListSQLDataBaseToolInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        tool_input: str = \"\",\n",
    "        run_manager: CallbackManagerForToolRun | None = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Get a comma-separated list of table names.\"\"\"\n",
    "        return \", \".join(self.db.get_usable_table_names())\n",
    "\n",
    "\n",
    "class _QuerySQLCheckerToolInput(BaseModel):\n",
    "    query: str = Field(..., description=\"A detailed and SQL query to be checked.\")\n",
    "\n",
    "\n",
    "class QuerySQLCheckerTool(BaseSQLDatabaseTool, BaseTool):  # type: ignore[override, override]\n",
    "    \"\"\"Use an LLM to check if a query is correct.\n",
    "    Adapted from https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/\"\"\"\n",
    "\n",
    "    template: str = QUERY_CHECKER\n",
    "    llm: BaseLanguageModel\n",
    "    llm_chain: Any = Field(init=False)\n",
    "    name: str = \"sql_db_query_checker\"\n",
    "    description: str = \"\"\"\n",
    "    Use this tool to double check if your query is correct before executing it.\n",
    "    Always use this tool before executing a query with sql_db_query!\n",
    "    \"\"\"\n",
    "    args_schema: Type[BaseModel] = _QuerySQLCheckerToolInput\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def initialize_llm_chain(cls, values: Dict[str, Any]) -> Any:\n",
    "        if \"llm_chain\" not in values:\n",
    "            from langchain.chains.llm import LLMChain\n",
    "\n",
    "            values[\"llm_chain\"] = LLMChain(\n",
    "                llm=values.get(\"llm\"),  # type: ignore[arg-type]\n",
    "                prompt=PromptTemplate(template=QUERY_CHECKER, input_variables=[\"dialect\", \"query\"]),\n",
    "            )\n",
    "\n",
    "        if values[\"llm_chain\"].prompt.input_variables != [\"dialect\", \"query\"]:\n",
    "            raise ValueError(\n",
    "                \"LLM chain for QueryCheckerTool must have input variables ['query', 'dialect']\"\n",
    "            )\n",
    "\n",
    "        return values\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: CallbackManagerForToolRun | None = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the LLM to check the query.\"\"\"\n",
    "        return self.llm_chain.predict(\n",
    "            query=query,\n",
    "            dialect=self.db.dialect,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "        )\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: AsyncCallbackManagerForToolRun | None = None,\n",
    "    ) -> str:\n",
    "        return await self.llm_chain.apredict(\n",
    "            query=query,\n",
    "            dialect=self.db.dialect,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_core.caches import BaseCache as BaseCache\n",
    "from langchain_core.callbacks import Callbacks as Callbacks\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.tools.base import BaseToolkit\n",
    "from pydantic import ConfigDict, Field\n",
    "\n",
    "\n",
    "class SQLDatabaseToolkit_query(BaseToolkit):\n",
    "    db: SQLDatabase = Field(exclude=True)\n",
    "    llm: BaseLanguageModel = Field(exclude=True)\n",
    "\n",
    "    @property\n",
    "    def dialect(self) -> str:\n",
    "        \"\"\"Return string representation of SQL dialect to use.\"\"\"\n",
    "        return self.db.dialect\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True,\n",
    "    )\n",
    "\n",
    "    def get_tools(self) -> List[BaseTool]:\n",
    "        \"\"\"Get the tools in the toolkit.\"\"\"\n",
    "        query_sql_database_tool_description = (\n",
    "            \"Input to this tool is a detailed and correct SQL query, output is a \"\n",
    "            \"result from the database. If the query is not correct, an error message \"\n",
    "            \"will be returned, rewrite the query, check the query, and try again.\"\n",
    "            \"VERY IMPORTANT! LIMIT your query results at most 20.\"\n",
    "        )\n",
    "        query_sql_database_tool = QuerySQLDataBaseTool(\n",
    "            db=self.db,\n",
    "            description=query_sql_database_tool_description,\n",
    "            response_format=\"content_and_artifact\",\n",
    "        )\n",
    "        query_sql_checker_tool_description = (\n",
    "            \"Use this tool to double check if your query is correct before executing \"\n",
    "            f\"it. Always use this tool before executing a query with {query_sql_database_tool.name}!\"\n",
    "            \"VERY IMPORTANT! LIMIT your query results at most 20.\"\n",
    "        )\n",
    "        query_sql_checker_tool = QuerySQLCheckerTool(\n",
    "            db=self.db, llm=self.llm, description=query_sql_checker_tool_description\n",
    "        )\n",
    "        info_sql_database_tool_description = (\n",
    "            \"Input to this tool is a comma-separated list of tables, output is the \"\n",
    "            \"schema and sample rows for those tables. \"\n",
    "            \"Example Input: table1, table2, table3\"\n",
    "        )\n",
    "        info_sql_database_tool = InfoSQLDatabaseTool(\n",
    "            db=self.db, description=info_sql_database_tool_description\n",
    "        )\n",
    "        return [\n",
    "            query_sql_database_tool,\n",
    "            info_sql_database_tool,\n",
    "            query_sql_checker_tool,\n",
    "        ]\n",
    "\n",
    "    def get_context(self) -> dict:\n",
    "        \"\"\"Return db context that you may want in agent prompt.\"\"\"\n",
    "        return self.db.get_context()\n",
    "\n",
    "\n",
    "class SQLDatabaseToolkit_schema(BaseToolkit):\n",
    "    db: SQLDatabase = Field(exclude=True)\n",
    "    llm: BaseLanguageModel = Field(exclude=True)\n",
    "\n",
    "    @property\n",
    "    def dialect(self) -> str:\n",
    "        \"\"\"Return string representation of SQL dialect to use.\"\"\"\n",
    "        return self.db.dialect\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True,\n",
    "    )\n",
    "\n",
    "    def get_tools(self) -> List[BaseTool]:\n",
    "        \"\"\"Get the tools in the toolkit.\"\"\"\n",
    "        info_sql_database_tool_description = (\n",
    "            \"Input to this tool is a comma-separated list of tables, output is the \"\n",
    "            \"schema and sample rows for those tables. \"\n",
    "            \"Example Input: table1, table2, table3\"\n",
    "        )\n",
    "        info_sql_database_tool = InfoSQLDatabaseTool(\n",
    "            db=self.db, description=info_sql_database_tool_description\n",
    "        )\n",
    "        return [\n",
    "            info_sql_database_tool,\n",
    "        ]\n",
    "\n",
    "    def get_context(self) -> dict:\n",
    "        \"\"\"Return db context that you may want in agent prompt.\"\"\"\n",
    "        return self.db.get_context()\n",
    "\n",
    "\n",
    "class SQLDatabaseToolkit_list(BaseToolkit):\n",
    "    db: SQLDatabase = Field(exclude=True)\n",
    "    llm: BaseLanguageModel = Field(exclude=True)\n",
    "\n",
    "    @property\n",
    "    def dialect(self) -> str:\n",
    "        \"\"\"Return string representation of SQL dialect to use.\"\"\"\n",
    "        return self.db.dialect\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True,\n",
    "    )\n",
    "\n",
    "    def get_tools(self) -> List[BaseTool]:\n",
    "        \"\"\"Get the tools in the toolkit.\"\"\"\n",
    "        info_list_sql_database_tool = \"Use this tool to list the table names in the dataset. \"\n",
    "        list_sql_database_tool = ListSQLDatabaseTool(\n",
    "            db=self.db, description=info_list_sql_database_tool\n",
    "        )\n",
    "\n",
    "        return [\n",
    "            list_sql_database_tool,\n",
    "        ]\n",
    "\n",
    "    def get_context(self) -> dict:\n",
    "        \"\"\"Return db context that you may want in agent prompt.\"\"\"\n",
    "        return self.db.get_context()\n",
    "\n",
    "\n",
    "SQLDatabaseToolkit_query.model_rebuild()\n",
    "SQLDatabaseToolkit_schema.model_rebuild()\n",
    "SQLDatabaseToolkit_list.model_rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_span = SQLDatabaseToolkit_schema(db=SQLDatabase(engine=engine), llm=llm).get_tools()\n",
    "tools_init = SQLDatabaseToolkit_list(db=SQLDatabase(engine=engine), llm=llm).get_tools()\n",
    "tools_execute = SQLDatabaseToolkit_query(db=SQLDatabase(engine=engine), llm=llm).get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from langchain_core.messages import HumanMessage, RemoveMessage, ToolMessage\n",
    "from langgraph.graph import END\n",
    "\n",
    "init_prompt = \"\"\"\n",
    "Return the list of all the table names.\n",
    "Do not contain any other words. Your response should exactly be of the form:\n",
    "table1, table2, table3, table4\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SearchingStrategy(Enum):\n",
    "    BREADTH_FIRST = 0\n",
    "    DEPTH_FIRST = 1\n",
    "\n",
    "\n",
    "def traverse(root: TreeState, searching_strategy=SearchingStrategy.BREADTH_FIRST):\n",
    "    \"\"\"returns a generator of agent tree traversal according to searching strategy\"\"\"\n",
    "    temp_node_list = [root]\n",
    "    if SearchingStrategy.BREADTH_FIRST == searching_strategy:\n",
    "        # Do BFS, use temp_node_list as a queue\n",
    "        while len(temp_node_list) != 0:\n",
    "            next_node = temp_node_list.pop(0)\n",
    "            if \"child_list\" in next_node:\n",
    "                temp_node_list.extend(next_node[\"child_list\"])\n",
    "            yield next_node\n",
    "    elif SearchingStrategy.DEPTH_FIRST == searching_strategy:\n",
    "        # Do DFS, use temp_node_list as a stack\n",
    "        while len(temp_node_list) != 0:\n",
    "            next_node = temp_node_list.pop(-1)\n",
    "            if \"child_list\" in next_node:\n",
    "                temp_node_list.extend(reversed(next_node[\"child_list\"]))\n",
    "            yield next_node\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def traverse_tree(state: TreeState) -> TreeState:\n",
    "    \"\"\"Traverse the tree to decide the next action to take.\"\"\"\n",
    "    # get table names first\n",
    "    if \"data_tables\" not in state or state[\"data_tables\"] is None:\n",
    "        if \"messages\" not in state or state[\"messages\"] == []:\n",
    "            state[\"messages\"] = [HumanMessage(init_prompt)]\n",
    "        llm_response = llm.bind_tools(tools_init).invoke(state[\"messages\"])\n",
    "        state[\"messages\"].append(llm_response)\n",
    "        if (\n",
    "            len(state[\"messages\"]) > 2\n",
    "            and isinstance(state[\"messages\"][-2], ToolMessage)\n",
    "            and state[\"messages\"][-2].name == \"sql_db_list_tables\"\n",
    "        ):\n",
    "            state[\"data_tables\"] = state[\"messages\"][-2].content\n",
    "            state[\"messages\"] = [RemoveMessage(id=m.id) for m in state[\"messages\"]]\n",
    "            state[\"next\"] = \"tree_traverser\"\n",
    "            return state\n",
    "        state[\"next\"] = \"tools_init\"\n",
    "        return state\n",
    "\n",
    "    for node in traverse(state):\n",
    "        if (\n",
    "            (\"respond\" not in node or node[\"respond\"] is None)\n",
    "            or \"child_list\" in node\n",
    "            and node[\"child_list\"] != []\n",
    "            and \"respond\" not in node[\"child_list\"][-1]\n",
    "        ):\n",
    "            return {\"next\": \"execute\"}\n",
    "\n",
    "        if node[\"focused_problem\"]:\n",
    "            if (\n",
    "                (\"child_list\" not in node or node[\"child_list\"] == [])\n",
    "                and node[\"height\"] < state[\"max_height\"]\n",
    "            ) or (\"expanded_id\" in state and state[\"expanded_id\"] == node[\"id\"]):\n",
    "                return {\"next\": \"span\"}\n",
    "\n",
    "    return {\"next\": END}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage, SystemMessage\n",
    "\n",
    "prefix_for_analysis_planning = \"\"\"\n",
    "You are an agent designed to interact with a SQL database and act as an excellent data scientist.\n",
    "Given an input problem, you should try to divide it into up to {max_subproblems} sub-problems.\n",
    "Each sub-problem should correspond to a single section in the report.\n",
    "For each sub-problem, you must just state the problem directly without any other information.\n",
    "\n",
    "Here are some hints for you:\n",
    "- Read the SQL schema, and think about what properties can be analyzed.\n",
    "- Check a column and consider how does a property change over time.\n",
    "- Are there any relationship between two columns?\n",
    "- Are there any noticeable value or trend in given data?\n",
    "\n",
    "You should not mention words like SQL table schema or SQL clauses, or output with json-like formats, or table column names etc, just give your sub-problems.\n",
    "Ensure the sub-problems are well-aligned with the input problem and data schema.\n",
    "Your sub-problems should be meaningful for analysis.\n",
    "Information like code, hot value and ID are meaningless. Information like number, price and quantity are meaningful.\n",
    "\n",
    "Upon listing the sub-problems, you should start with \"Final Answer:\", and then state the n-th sub-problem by starting with 'Sub-problem n:', followed by\n",
    "the sub-problem. You should only use this format in your final answer:\n",
    "Final Answer:\n",
    "Sub-problem 1: ...\n",
    "Sub-problem 2: ...\n",
    "\"\"\"\n",
    "\n",
    "suffix_for_exclusion = \"\"\"\n",
    "Previous problem list (marked with **):\n",
    "{previous_sub_problems}\n",
    "\n",
    "VERY IMPORTANT! Please follow these instructions:\n",
    "\n",
    "1. The user's input `problem` might be one of the existing problems in the previous problem list. Treat it as a valid input.\n",
    "2. Generate DISTINCT sub-problems based on the input `problem`. Sub-problems MUST NOT be identical or overly similar to any problem in the previous problem list.\n",
    "3. Focus on creating NEW sub-problems related to the input, even if the input matches a problem in the previous problem list.\n",
    "\n",
    "Examples:\n",
    "1. Input: Analyze the effects of climate change. (from the list)\n",
    "   - Existing problems:\n",
    "     - **Analyze the effects of climate change.\n",
    "     - **Study the causes of global warming.\n",
    "   - Output (Correct):\n",
    "    Final Answer:\n",
    "    Sub-problem 1: Investigate strategies to mitigate climate change.\n",
    "    Sub-problem 2: Examine the economic impact of climate adaptation.\n",
    "\n",
    "2. Input: Study the impact of renewable energy adoption. (not from the list)\n",
    "   - Existing problems:\n",
    "     - **Analyze barriers to renewable energy adoption.\n",
    "   - Output (Correct):\n",
    "    Final Answer:\n",
    "    Sub-problem 1: Evaluate the role of policy in renewable energy growth.\n",
    "    Sub-problem 2: Assess the social acceptance of renewable technologies.\n",
    "\"\"\"\n",
    "\n",
    "table_name_info = \"\"\"\n",
    "When interacting with SQL tools to fetch schema details, make sure to only consider the following tables:\n",
    "{table_names}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def output_parser_division(ori_problem: str, parent_height: int, message: str) -> List[\"TreeState\"]:\n",
    "    ret = [\n",
    "        TreeState(\n",
    "            id=uuid.uuid4(),\n",
    "            focused_problem=s[3:],\n",
    "            child_list=[],\n",
    "            original_problem=ori_problem,\n",
    "            height=parent_height + 1,\n",
    "        )\n",
    "        for s in message.split(\"Sub-problem \")[1:]\n",
    "    ]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def divide_problem(state: TreeState) -> TreeState:\n",
    "    \"\"\"Generate the subproblems given the original problem.\"\"\"\n",
    "    if \"messages\" not in state or state[\"messages\"] == []:\n",
    "        focused_node = None\n",
    "        for node in traverse(state):\n",
    "            if (\n",
    "                (\"child_list\" not in node or node[\"child_list\"] == [])\n",
    "                and node[\"height\"] < state[\"max_height\"]\n",
    "            ) or (\"expanded_id\" in state and state[\"expanded_id\"] == node[\"id\"]):\n",
    "                focused_node = node\n",
    "                break\n",
    "        focused_problem = \"\\n\" + focused_node[\"focused_problem\"] + \"\\n\"\n",
    "        return {\"messages\": [HumanMessage(focused_problem)]}\n",
    "\n",
    "    max_subproblems = 2  # default\n",
    "    if \"max_subproblems\" in state:\n",
    "        max_subproblems = state[\"max_subproblems\"]\n",
    "    if \"first_level_subproblems\" in state and (\n",
    "        \"child_list\" not in state or state[\"child_list\"] == []\n",
    "    ):  # root span\n",
    "        max_subproblems = state[\"first_level_subproblems\"]\n",
    "\n",
    "    _prefix_for_analysis_planning = prefix_for_analysis_planning.format(\n",
    "        max_subproblems=max_subproblems\n",
    "    )\n",
    "    system_message = SystemMessage(content=_prefix_for_analysis_planning)\n",
    "    messages = [system_message]\n",
    "    if len(state[\"messages\"]) > 0 and (\n",
    "        isinstance(state[\"messages\"][-1], HumanMessage) or \"Error:\" in state[\"messages\"][-1].content\n",
    "    ):\n",
    "        if \"prev_questions\" in state and state[\"prev_questions\"] != []:\n",
    "            _suffix_for_exclusion = suffix_for_exclusion.format(\n",
    "                previous_sub_problems=\"\\n\".join(state[\"prev_questions\"])\n",
    "            )\n",
    "            messages.append(SystemMessage(content=_suffix_for_exclusion))\n",
    "        messages.append(SystemMessage(table_name_info.format(table_names=state[\"data_tables\"])))\n",
    "\n",
    "    if len(state[\"messages\"]) > 0:\n",
    "        messages.append(state[\"messages\"][0])\n",
    "    if len(state[\"messages\"]) > 1:\n",
    "        # append last tool msg\n",
    "        prev_tool_msg = []\n",
    "        for m in state[\"messages\"][::-1]:\n",
    "            prev_tool_msg.append(m)\n",
    "            if isinstance(m, AIMessage):\n",
    "                break\n",
    "        messages += prev_tool_msg[::-1]\n",
    "    llm_response = llm.bind_tools(tools_span).invoke(messages)\n",
    "\n",
    "    if hasattr(llm_response, \"tool_calls\") and len(llm_response.tool_calls) > 0:\n",
    "        return {\"messages\": [llm_response]}\n",
    "\n",
    "    for node in traverse(state):\n",
    "        if (\n",
    "            (\"child_list\" not in node or node[\"child_list\"] == [])\n",
    "            and node[\"height\"] < state[\"max_height\"]\n",
    "        ) or (\"expanded_id\" in state and state[\"expanded_id\"] == node[\"id\"]):\n",
    "            for child in output_parser_division(\n",
    "                node[\"focused_problem\"], node[\"height\"], llm_response.content\n",
    "            ):\n",
    "                node[\"child_list\"].append(child)\n",
    "                state[\"prev_questions\"].append(\"**\" + child[\"focused_problem\"])\n",
    "            break\n",
    "    state[\"messages\"] = [RemoveMessage(id=m.id) for m in state[\"messages\"]]\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "from json import JSONDecodeError\n",
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "def sanitize_input(query: str) -> str:\n",
    "    \"\"\"Sanitize input to the python REPL.\n",
    "\n",
    "    Remove whitespace, backtick & python (if llm mistakes python console as terminal)\n",
    "\n",
    "    Args:\n",
    "        query: The query to sanitize\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized query\n",
    "    \"\"\"\n",
    "\n",
    "    # Removes `, whitespace & python from start\n",
    "    query = re.sub(r\"^(\\s|`)*(?i:python)?\\s*\", \"\", query)\n",
    "    # Removes whitespace & ` from end\n",
    "    query = re.sub(r\"(\\s|`)*$\", \"\", query)\n",
    "    return query\n",
    "\n",
    "\n",
    "class Echarts:\n",
    "    def __init__(self, result: Any | None):\n",
    "        self._result = result\n",
    "\n",
    "    def run(self, script: str) -> Dict | str:\n",
    "        \"\"\"\n",
    "        Use to run a python script for generating an Echarts options dict\n",
    "        and return the dict.\n",
    "        \"\"\"\n",
    "        locals = {\"result\": eval(self._result), \"pd\": pd}\n",
    "        try:\n",
    "            query = sanitize_input(script)\n",
    "            tree = ast.parse(query)\n",
    "            module_end = ast.Module(tree.body[-1:], type_ignores=[])\n",
    "            if not module_end.body or not isinstance(module_end.body[0], ast.Expr):\n",
    "                raise self.ResultNotFoundException()\n",
    "            module = ast.Module(tree.body[:-1], type_ignores=[])\n",
    "            exec(ast.unparse(module), locals)  # type: ignore\n",
    "            module_end_str = ast.unparse(module_end)  # type: ignore\n",
    "            io_buffer = StringIO()\n",
    "            has_json_decode_err = False\n",
    "            try:\n",
    "                json.loads(module_end_str)\n",
    "            except JSONDecodeError:\n",
    "                has_json_decode_err = True\n",
    "            if not has_json_decode_err:\n",
    "                # 只要大模型生成的代码中用到了上面的变量，则最后的变量用Json解析是必然会出错的\n",
    "                # 如果没出错，说明它直接加载了数据\n",
    "                raise self.DataframeNotUsedException()\n",
    "            try:\n",
    "                with redirect_stdout(io_buffer):\n",
    "                    ret = eval(module_end_str, locals)\n",
    "                    if ret is None:\n",
    "                        ret = io_buffer.getvalue()\n",
    "                    assert isinstance(ret, Dict)\n",
    "                    return ret\n",
    "            except Exception:\n",
    "                with redirect_stdout(io_buffer):\n",
    "                    exec(module_end_str, locals)\n",
    "                ret = io_buffer.getvalue()\n",
    "                assert isinstance(ret, Dict)\n",
    "                return ret\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return f\"{type(e).__name__}: {str(e)}\"\n",
    "\n",
    "    class ResultNotFoundException(Exception):\n",
    "        def __init__(self):\n",
    "            super().__init__(\n",
    "                \"Please write the variable name of the echarts options dict in the last line.\"\n",
    "            )\n",
    "\n",
    "    class DataframeNotUsedException(Exception):\n",
    "        def __init__(self):\n",
    "            super().__init__(\n",
    "                \"Please write python script to load data into the echarts options dict \"\n",
    "                \"rather than write data directly to the dict.\"\n",
    "            )\n",
    "\n",
    "\n",
    "def show_table(tool_call_msg: AIMessage, tool_msg: ToolMessage):\n",
    "    tool_call_id = tool_msg.tool_call_id\n",
    "    tool_calls = tool_call_msg.additional_kwargs[\"tool_calls\"]\n",
    "    tool_call_content = None\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call[\"id\"] == tool_call_id:\n",
    "            tool_call_content = tool_call\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        query = json.loads(tool_call_content[\"function\"][\"arguments\"])[\"query\"]\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        query = None\n",
    "    artifact = TableArtifact(query=query, result=tool_msg.artifact)\n",
    "    # print(\"artifact here: \", artifact)\n",
    "    return artifact\n",
    "\n",
    "\n",
    "def show_charts(script: str, tool_call_msg: AIMessage, tool_msg: ToolMessage):\n",
    "    tool_call_id = tool_msg.tool_call_id\n",
    "    tool_calls = tool_call_msg.additional_kwargs[\"tool_calls\"]\n",
    "    tool_call_content = None\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call[\"id\"] == tool_call_id:\n",
    "            tool_call_content = tool_call\n",
    "            break\n",
    "    try:\n",
    "        options_dict = Echarts(tool_msg.artifact).run(script)\n",
    "        if isinstance(options_dict, str):\n",
    "            return options_dict, None\n",
    "        try:\n",
    "            query = json.loads(tool_call_content[\"function\"][\"arguments\"])[\"query\"]\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            query = None\n",
    "        artifact = ChartArtifact(\n",
    "            query=query,\n",
    "            options=options_dict,\n",
    "            vis_script=script,\n",
    "        )\n",
    "        return artifact\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a992646",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlevel_prefix = \"\"\"Your are an excellent data scientist agent for business intelligence.\n",
    "You are responsible for writing section(s) of a report related to the given problem(s).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sql_agent_prefix = \"\"\"Given the input problem(s), create syntactically correct SQL queries to run, then look at the results of the query\n",
    "and return the answers.\n",
    "You can order the query results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the problem.\n",
    "You have access to tools for interacting with the database. Please make full use of them.\n",
    "Pay attention to use functions to get current date, current month or current year, if the problem does not explicitly provide a date.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "For the input problem(s), look at the tables in the database to see what you can query.\n",
    "and use 'sql_db_schema' to retrieve the schema of the most relevant tables first.\n",
    "Query for meaningful table columns. Information like code, hot value and ID are meaningless. Information like price, quantity and so on are meaningful.\n",
    "If get schema successfully, call 'sql_db_query_checker' to write and validate query that strongly related to the problem and schema.\n",
    "If 'sql_db_query_checker' returns right queries, call 'sql_db_query' to get the data result.\n",
    "\n",
    "VERY IMPORTANT! If a table contains both ID and name columns,\n",
    "you MUST query for the name rather than ID because no one understands meanings of IDs.\n",
    "VERY IMPORTANT! If the input problem asks you to predict something\n",
    "(e.g., an input contains word `will`), you should answer it based on your analysis but do not try to query it\n",
    "directly because the data user wants does not actually exist.\n",
    "VERY IMPORTANT! Unless the user specifies the exact number of examples they want, always limit your response to a maximum of 5 results.\n",
    "Even if the user requests a specific number of examples, do not provide more than 20 results under any circumstances.\n",
    "\n",
    "In this current stage, do not write anything, always call tools. Do not give the final conclusion.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "answer_format_info = \"\"\"\n",
    "Now you should not call Tools anymore. You need to use previous query result to give section content.\n",
    "DO NOT mention words like SQL table schema or SQL clauses, or output with json-like formats, etc, just give your section(s).\n",
    "Your answer should solely based on actual data of SQL results without general information.\n",
    "Your answer should be a meaningful analysis.\n",
    "Information like code, hot value and ID are meaningless. Information like number, price and quantity are meaningful.\n",
    "\n",
    "For each section, give suitable visualization suggestion according to the problem and query result.\n",
    "Only give suggestion, do not really visualize the data.\n",
    "You have 3 choices for visualization: 'table', 'chart', 'none', all in lowercase. Write your choice after '**Vis n: '.\n",
    "If not specified, use a table when precise values and detailed comparisons are needed.\n",
    "If not specified, use a chart when highlighting trends, relationships, or making comparison.\n",
    "Use none if get no query result or Error.\n",
    "Counting from 1, for N sections, suppose retrieved X ToolMessages, you should indicate x-th ToolMessage corresponding to n-th section, write: '**Tool n: x'.\n",
    "If there are multiple ToolMessages correspond to one section, only save the first non-empty ToolMessage if exists.\n",
    "\n",
    "If retrieved query result data for some problem is empty, error or meaningless, do not write any section content. Leave that section empty like:\n",
    "**Section n:\n",
    "**Vis n: none\n",
    "**Tool n: 0\n",
    "\n",
    "***VERY IMPORTANT!!! The total number of section(s) should strictly be the same as the total number of the input problem(s).\n",
    "***VERY IMPORTANT!!! Start your answer by 'Final Answer:'. Your final response MUST strictly follow this format:\n",
    "Final Answer:\n",
    "**Section 1: ...\n",
    "**Vis 1: ...\n",
    "**Tool 1: ...\n",
    "**Section 2: ...\n",
    "**Vis 2: ...\n",
    "**Tool 2: ...\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "script_writing_prompt = \"\"\"\n",
    "You are an outstanding python developer who understands data well with a good command of Apache Echarts.\n",
    "The result of last query has been stored in variable `result`,\n",
    "you should write Python script to load data from variable `result` to\n",
    "an echarts options dict (not json string) to display these data.\n",
    "IMPORTANT! Do not write constants in your code directly.\n",
    "You must use your code to load value from variable `result`.\n",
    "\n",
    "Please select an appropriate chart type.\n",
    "You should always add appropriate tooltips for your chart.\n",
    "You should output your code only.\n",
    "\n",
    "Output Instruction:\n",
    "1. Remember to import necessary packages in your code if needed.\n",
    "For example:\n",
    "from decimal import Decimal\n",
    "\n",
    "2. Do NOT import pyecharts!!!\n",
    "\n",
    "3. You should write the variable name of the echarts options dict in the last line.\n",
    "You should output your echarts options as dict. The echarts option dict of your output should be of the format like:\n",
    "option = {\n",
    "    'tooltip': {\n",
    "        'trigger': ...,\n",
    "        'axisPointer': {\n",
    "            'type': ...,\n",
    "            ...\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    'legend': {\n",
    "        'data': ...,\n",
    "        ...\n",
    "    },\n",
    "    'xAxis': {\n",
    "        'type': ...,\n",
    "        'data': ...,\n",
    "        ...\n",
    "    },\n",
    "    'yAxis': {\n",
    "        'type': ...,\n",
    "        ...\n",
    "    },\n",
    "    'series': [\n",
    "        {\n",
    "            'name': ...,\n",
    "            'type': ...,\n",
    "            'data': ...,\n",
    "            ...\n",
    "        },\n",
    "        ...\n",
    "    ],\n",
    "    'tooltip': {\n",
    "        'trigger': ...,\n",
    "        'formatter': ...,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "\n",
    "option\n",
    "\"\"\"\n",
    "\n",
    "table_name_info = \"\"\"\n",
    "When interacting with SQL tools to fetch schema details, make sure to only consider the following tables:\n",
    "{table_names}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def output_parser(focused_node, last_tool_msg, llm_response):\n",
    "    nth_node = 0\n",
    "    for child in focused_node[\"child_list\"]:\n",
    "        if \"respond\" in child:\n",
    "            nth_node += 1\n",
    "    for content in llm_response.content.split(\"**Section \")[1:]:\n",
    "        paragraph = content.split(\"**Vis \")[0][3:].strip()\n",
    "        vis_choice = content.split(\"**Vis \")[1][3:].split(\"**Tool \")[0]\n",
    "        tool_order = int(content.split(\"**Tool \")[1][3:])\n",
    "        focused_node[\"child_list\"][nth_node][\"respond\"] = paragraph\n",
    "        if \"table\" in vis_choice:\n",
    "            focused_node[\"child_list\"][nth_node][\"artifact_type\"] = \"table\"\n",
    "            if tool_order <= len(last_tool_msg) - 1:\n",
    "                tool_call_msg = last_tool_msg[0]\n",
    "                tool_msg = last_tool_msg[tool_order]\n",
    "                focused_node[\"child_list\"][nth_node][\"artifact\"] = show_table(\n",
    "                    tool_call_msg, tool_msg\n",
    "                )\n",
    "        elif \"chart\" in vis_choice:\n",
    "            focused_node[\"child_list\"][nth_node][\"artifact_type\"] = \"chart\"\n",
    "            if tool_order <= len(last_tool_msg) - 1:\n",
    "                tool_call_msg = last_tool_msg[0]\n",
    "                tool_msg = last_tool_msg[tool_order]\n",
    "                prompt = llm.invoke([SystemMessage(script_writing_prompt)] + last_tool_msg).content\n",
    "                focused_node[\"child_list\"][nth_node][\"artifact\"] = show_charts(\n",
    "                    prompt, tool_call_msg, tool_msg\n",
    "                )\n",
    "        nth_node += 1\n",
    "\n",
    "\n",
    "def solve_problem(state: TreeState) -> TreeState:\n",
    "    \"\"\"Solve each sub-problem based on selected tools.\"\"\"\n",
    "    # retrieve messages related to the current sub-problem\n",
    "    if \"messages\" not in state or state[\"messages\"] == []:\n",
    "        if \"respond\" not in state:  # empty state\n",
    "            focused_problem = \"\\nProblem 1: \" + state[\"focused_problem\"] + \"\\n\"\n",
    "            return {\"messages\": [HumanMessage(focused_problem)]}\n",
    "        focused_node = None  # none empty state\n",
    "        for node in traverse(state):\n",
    "            if (\n",
    "                \"child_list\" in node\n",
    "                and node[\"child_list\"] != []\n",
    "                and \"respond\" not in node[\"child_list\"][-1]\n",
    "            ):\n",
    "                focused_node = node\n",
    "                break\n",
    "        focused_problem = \"\"\n",
    "        problem_no = 1\n",
    "        for child_node in focused_node[\"child_list\"]:\n",
    "            if \"respond\" not in child_node:\n",
    "                focused_problem += (\n",
    "                    \"\\nProblem \" + str(problem_no) + \": \" + child_node[\"focused_problem\"] + \"\\n\"\n",
    "                )\n",
    "                problem_no += 1\n",
    "        return {\"messages\": [HumanMessage(focused_problem)]}\n",
    "\n",
    "    last_tool_msg = []\n",
    "    if len(state[\"messages\"]) > 1:\n",
    "        # append last tool msg\n",
    "        prev_tool_msg = []\n",
    "        for m in state[\"messages\"][::-1]:\n",
    "            prev_tool_msg.append(m)\n",
    "            if isinstance(m, AIMessage):\n",
    "                break\n",
    "        last_tool_msg += prev_tool_msg[::-1]\n",
    "    get_query = False\n",
    "    for tool_msg in last_tool_msg:\n",
    "        if tool_msg.name == \"sql_db_query\":\n",
    "            get_query = True\n",
    "\n",
    "    highlevel_message = SystemMessage(content=highlevel_prefix)\n",
    "    if get_query:\n",
    "        system_message = SystemMessage(content=answer_format_info)\n",
    "    else:\n",
    "        system_message = SystemMessage(content=sql_agent_prefix)\n",
    "    messages = [highlevel_message, system_message]\n",
    "\n",
    "    if len(state[\"messages\"]) > 0 and (\n",
    "        isinstance(state[\"messages\"][-1], HumanMessage)\n",
    "        or (\n",
    "            \"Error:\" in state[\"messages\"][-1].content\n",
    "            and state[\"messages\"][-1].name == \"sql_db_schema\"\n",
    "        )\n",
    "    ):\n",
    "        messages.append(SystemMessage(table_name_info.format(table_names=state[\"data_tables\"])))\n",
    "\n",
    "    if len(state[\"messages\"]) > 0:\n",
    "        messages.append(state[\"messages\"][0])\n",
    "\n",
    "    if get_query:\n",
    "        llm_response = llm.invoke(messages + last_tool_msg)\n",
    "    else:\n",
    "        llm_response = llm.bind_tools(tools_execute).invoke(messages + last_tool_msg)\n",
    "\n",
    "    # DO NOT REGENERATE TEMPORARILY DUE TO TOKEN COST ISSUE\n",
    "    # if state['height'] > 0 and state['messages'][-1].name == 'sql_db_query' and \\\n",
    "    #   (state['messages'][-1].content is None or state['messages'][-1].content == ''):\n",
    "    #     # regenerate subproblem due to empty query result\n",
    "    #     if state['regenerate_times'] < 1:\n",
    "    #         state['messages'] = [RemoveMessage(id=m.id) for m in state['messages']]\n",
    "    #         state['regenerate_times'] += 1\n",
    "    #         return state\n",
    "    #     # regenrate too much times, just ignore\n",
    "    #     else:\n",
    "    #         state['regenerate_times'] = 0\n",
    "\n",
    "    if hasattr(llm_response, \"tool_calls\") and len(llm_response.tool_calls) > 0:\n",
    "        # has more tool call request\n",
    "        return {\"messages\": [llm_response]}\n",
    "    # no more tool call request, go to the next node\n",
    "    if \"respond\" not in state:  # for root\n",
    "        if not (\n",
    "            \"**Section \" in llm_response.content\n",
    "            and \"**Vis \" in llm_response.content\n",
    "            and \"**Tool \" in llm_response.content\n",
    "        ):\n",
    "            raise ValueError(\"LLM paragraph response format error\")\n",
    "        content = llm_response.content.split(\"**Section \")[1]\n",
    "        paragraph = content.split(\"**Vis \")[0][3:].strip()\n",
    "        vis_choice = content.split(\"**Vis \")[1][3:].split(\"**Tool \")[0]\n",
    "        tool_order = int(content.split(\"**Tool \")[1][3:])\n",
    "        state[\"respond\"] = paragraph\n",
    "        if \"table\" in vis_choice:\n",
    "            # state['artifact_type'] = 'chart'\n",
    "            # if tool_order <= len(last_tool_msg) - 1:\n",
    "            #     tool_call_msg = last_tool_msg[0]\n",
    "            #     tool_msg = last_tool_msg[tool_order]\n",
    "            #     prompt = llm.invoke([SystemMessage(script_writing_prompt)] + last_tool_msg).content\n",
    "            #     state['artifact'] = show_charts(prompt, tool_call_msg, tool_msg)\n",
    "            state[\"artifact_type\"] = \"table\"\n",
    "            if tool_order <= len(last_tool_msg) - 1:\n",
    "                tool_call_msg = last_tool_msg[0]\n",
    "                tool_msg = last_tool_msg[tool_order]\n",
    "                state[\"artifact\"] = show_table(tool_call_msg, tool_msg)\n",
    "        elif \"chart\" in vis_choice:\n",
    "            state[\"artifact_type\"] = \"chart\"\n",
    "            if tool_order <= len(last_tool_msg) - 1:\n",
    "                tool_call_msg = last_tool_msg[0]\n",
    "                tool_msg = last_tool_msg[tool_order]\n",
    "                prompt = llm.invoke([SystemMessage(script_writing_prompt)] + last_tool_msg).content\n",
    "                state[\"artifact\"] = show_charts(prompt, tool_call_msg, tool_msg)\n",
    "    else:  # none leaf node\n",
    "        for node in traverse(state):\n",
    "            if (\n",
    "                \"child_list\" in node\n",
    "                and node[\"child_list\"] != []\n",
    "                and \"respond\" not in node[\"child_list\"][-1]\n",
    "            ):\n",
    "                output_parser(node, last_tool_msg, llm_response)\n",
    "                break\n",
    "    if \"expanded_id\" in state:\n",
    "        state[\"expanded_id\"] = None\n",
    "\n",
    "    state[\"messages\"] = [RemoveMessage(id=m.id) for m in state[\"messages\"]]\n",
    "    # state['regenerate_times'] = 0\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ee109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "use_tools_init = ToolNode(tools=tools_init)\n",
    "use_tools_span = ToolNode(tools=tools_span)\n",
    "# use_tools_regenerate = ToolNode(tools=tools_regenerate)\n",
    "use_tools_execute = ToolNode(tools=tools_execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "\n",
    "def route_span(\n",
    "    state: TreeState,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the next.\n",
    "    \"\"\"\n",
    "    if state[\"messages\"] == []:\n",
    "        return \"tree_traverser\"\n",
    "    elif type(state[\"messages\"][-1]) == HumanMessage:\n",
    "        return \"span\"\n",
    "    else:\n",
    "        return \"tools_span\"\n",
    "\n",
    "\n",
    "# def route_regenerate(\n",
    "#         state: TreeState,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Use in the conditional_edge to route to the ToolNode if the last message\n",
    "#     has tool calls. Otherwise, route to the next.\n",
    "#     \"\"\"\n",
    "#     if state['messages'] == []:\n",
    "#         return 'execute'\n",
    "#     elif type(state['messages'][-1]) == HumanMessage:\n",
    "#         return \"regenerate\"\n",
    "#     else:\n",
    "#         return \"tools_span\"\n",
    "\n",
    "\n",
    "def route_execute(\n",
    "    state: TreeState,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the next.\n",
    "    \"\"\"\n",
    "    if state[\"messages\"] == []:\n",
    "        # if state['regenerate_times'] > 0:\n",
    "        #     return 'regenerate'\n",
    "        return \"tree_traverser\"\n",
    "    if type(state[\"messages\"][-1]) == HumanMessage:\n",
    "        return \"execute\"\n",
    "    else:\n",
    "        return \"tools_execute\"\n",
    "\n",
    "\n",
    "builder = StateGraph(TreeState)\n",
    "builder.add_node(\"tree_traverser\", traverse_tree)\n",
    "builder.add_node(\"span\", divide_problem)\n",
    "builder.add_node(\"execute\", solve_problem)\n",
    "# builder.add_node(\"regenerate\", regenerate_problem)\n",
    "# builder.add_node(\"summarize\", summarize_subproblems)\n",
    "builder.add_node(\"tools_init\", use_tools_init)\n",
    "builder.add_node(\"tools_span\", use_tools_span)\n",
    "# builder.add_node(\"tools_regenerate\", use_tools_regenerate)\n",
    "builder.add_node(\"tools_execute\", use_tools_execute)\n",
    "\n",
    "builder.add_edge(START, \"tree_traverser\")\n",
    "builder.add_conditional_edges(\"tree_traverser\", lambda state: state[\"next\"])\n",
    "builder.add_conditional_edges(\n",
    "    \"span\",\n",
    "    route_span,\n",
    "    {\"span\": \"span\", \"tools_span\": \"tools_span\", \"tree_traverser\": \"tree_traverser\"},\n",
    ")\n",
    "# builder.add_conditional_edges(\n",
    "#     \"regenerate\",\n",
    "#     route_regenerate,\n",
    "#     {\"regenerate\": \"regenerate\", \"tools_regenerate\": \"tools_regenerate\", 'execute': 'execute'},\n",
    "# )\n",
    "builder.add_conditional_edges(\n",
    "    \"execute\",\n",
    "    route_execute,\n",
    "    {\n",
    "        \"execute\": \"execute\",\n",
    "        \"tools_execute\": \"tools_execute\",\n",
    "        \"tree_traverser\": \"tree_traverser\",\n",
    "    },  # 'regenerate': 'regenerate'},\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools_init\", \"tree_traverser\")\n",
    "builder.add_edge(\"tools_span\", \"span\")\n",
    "# builder.add_edge(\"tools_regenerate\", \"regenerate\")\n",
    "builder.add_edge(\"tools_execute\", \"execute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7034733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "agent = builder.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb206f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_query = \"Conduct a detailed analysis of orders.\"\n",
    "\n",
    "\n",
    "root = TreeState(\n",
    "    id=uuid.uuid4(),\n",
    "    max_height=1,\n",
    "    focused_problem=example_query,\n",
    "    height=0,\n",
    "    prev_questions=[\"**\" + str(example_query) + \"\\n\"],\n",
    "    regenerate_times=0,\n",
    "    max_subproblems=4,\n",
    "    first_level_subproblems=2,\n",
    "    child_list=[],\n",
    ")\n",
    "\n",
    "config_thread = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013684a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_thread += 1\n",
    "config = {\n",
    "    \"configurable\": {\"thread_id\": config_thread},\n",
    "    \"recursion_limit\": 50,\n",
    "}\n",
    "print(root, config)\n",
    "\n",
    "for step in agent.stream(root, config):\n",
    "    print(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
