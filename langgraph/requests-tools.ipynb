{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587240c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.requests.tool import BaseRequestsTool\n",
    "from langchain_core.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa02336",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUESTS_GET_TOOL_DESCRIPTION = \"\"\"Use this to GET content from a website.\n",
    "Input to the tool should be a json string with 3 keys: \"url\", \"params\" and \"output_instructions\".\n",
    "The value of \"url\" should be a string. \n",
    "The value of \"params\" should be a dict of the needed and available parameters from the OpenAPI spec related to the endpoint. \n",
    "If parameters are not needed, or not available, leave it empty.\n",
    "The value of \"output_instructions\" should be instructions on what information to extract from the response, \n",
    "for example the id(s) for a resource(s) that the GET request fetches.\n",
    "\"\"\"\n",
    "MAX_RESPONSE_LENGTH = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestsGetToolWithParsing(BaseRequestsTool, BaseTool):\n",
    "    \"\"\"Requests GET tool with LLM-instructed extraction of truncated responses.\"\"\"\n",
    "\n",
    "    name: str = \"requests_get\"\n",
    "    \"\"\"Tool name.\"\"\"\n",
    "    description: str = REQUESTS_GET_TOOL_DESCRIPTION\n",
    "    \"\"\"Tool description.\"\"\"\n",
    "\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        from langchain.output_parsers.json import parse_json_markdown\n",
    "\n",
    "        try:\n",
    "            data = parse_json_markdown(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "        data_params = data.get(\"params\")\n",
    "        response: str = cast(str, self.requests_wrapper.get(data[\"url\"], params=data_params))\n",
    "        response = response[: self.response_length]\n",
    "        return self.llm_chain.predict(\n",
    "            response=response, instructions=data[\"output_instructions\"]\n",
    "        ).strip()\n",
    "\n",
    "    async def _arun(self, text: str) -> str:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestsPostToolWithParsing(BaseRequestsTool, BaseTool):\n",
    "    \"\"\"Requests POST tool with LLM-instructed extraction of truncated responses.\"\"\"\n",
    "\n",
    "    name: str = \"requests_post\"\n",
    "    \"\"\"Tool name.\"\"\"\n",
    "    description: str = REQUESTS_POST_TOOL_DESCRIPTION\n",
    "    \"\"\"Tool description.\"\"\"\n",
    "    response_length: int = MAX_RESPONSE_LENGTH\n",
    "    \"\"\"Maximum length of the response to be returned.\"\"\"\n",
    "    llm_chain: Any = Field(default_factory=_get_default_llm_chain_factory(PARSING_POST_PROMPT))\n",
    "    \"\"\"LLMChain used to extract the response.\"\"\"\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        from langchain.output_parsers.json import parse_json_markdown\n",
    "\n",
    "        try:\n",
    "            data = parse_json_markdown(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "        response: str = cast(str, self.requests_wrapper.post(data[\"url\"], data[\"data\"]))\n",
    "        response = response[: self.response_length]\n",
    "        return self.llm_chain.predict(\n",
    "            response=response, instructions=data[\"output_instructions\"]\n",
    "        ).strip()\n",
    "\n",
    "    async def _arun(self, text: str) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class RequestsPatchToolWithParsing(BaseRequestsTool, BaseTool):\n",
    "    \"\"\"Requests PATCH tool with LLM-instructed extraction of truncated responses.\"\"\"\n",
    "\n",
    "    name: str = \"requests_patch\"\n",
    "    \"\"\"Tool name.\"\"\"\n",
    "    description: str = REQUESTS_PATCH_TOOL_DESCRIPTION\n",
    "    \"\"\"Tool description.\"\"\"\n",
    "    response_length: int = MAX_RESPONSE_LENGTH\n",
    "    \"\"\"Maximum length of the response to be returned.\"\"\"\n",
    "    llm_chain: Any = Field(default_factory=_get_default_llm_chain_factory(PARSING_PATCH_PROMPT))\n",
    "    \"\"\"LLMChain used to extract the response.\"\"\"\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        from langchain.output_parsers.json import parse_json_markdown\n",
    "\n",
    "        try:\n",
    "            data = parse_json_markdown(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "        response: str = cast(str, self.requests_wrapper.patch(data[\"url\"], data[\"data\"]))\n",
    "        response = response[: self.response_length]\n",
    "        return self.llm_chain.predict(\n",
    "            response=response, instructions=data[\"output_instructions\"]\n",
    "        ).strip()\n",
    "\n",
    "    async def _arun(self, text: str) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class RequestsPutToolWithParsing(BaseRequestsTool, BaseTool):\n",
    "    \"\"\"Requests PUT tool with LLM-instructed extraction of truncated responses.\"\"\"\n",
    "\n",
    "    name: str = \"requests_put\"\n",
    "    \"\"\"Tool name.\"\"\"\n",
    "    description: str = REQUESTS_PUT_TOOL_DESCRIPTION\n",
    "    \"\"\"Tool description.\"\"\"\n",
    "    response_length: int = MAX_RESPONSE_LENGTH\n",
    "    \"\"\"Maximum length of the response to be returned.\"\"\"\n",
    "    llm_chain: Any = Field(default_factory=_get_default_llm_chain_factory(PARSING_PUT_PROMPT))\n",
    "    \"\"\"LLMChain used to extract the response.\"\"\"\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        from langchain.output_parsers.json import parse_json_markdown\n",
    "\n",
    "        try:\n",
    "            data = parse_json_markdown(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "        response: str = cast(str, self.requests_wrapper.put(data[\"url\"], data[\"data\"]))\n",
    "        response = response[: self.response_length]\n",
    "        return self.llm_chain.predict(\n",
    "            response=response, instructions=data[\"output_instructions\"]\n",
    "        ).strip()\n",
    "\n",
    "    async def _arun(self, text: str) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class RequestsDeleteToolWithParsing(BaseRequestsTool, BaseTool):\n",
    "    \"\"\"Tool that sends a DELETE request and parses the response.\"\"\"\n",
    "\n",
    "    name: str = \"requests_delete\"\n",
    "    \"\"\"The name of the tool.\"\"\"\n",
    "    description: str = REQUESTS_DELETE_TOOL_DESCRIPTION\n",
    "    \"\"\"The description of the tool.\"\"\"\n",
    "\n",
    "    response_length: Optional[int] = MAX_RESPONSE_LENGTH\n",
    "    \"\"\"The maximum length of the response.\"\"\"\n",
    "    llm_chain: Any = Field(default_factory=_get_default_llm_chain_factory(PARSING_DELETE_PROMPT))\n",
    "    \"\"\"The LLM chain used to parse the response.\"\"\"\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        from langchain.output_parsers.json import parse_json_markdown\n",
    "\n",
    "        try:\n",
    "            data = parse_json_markdown(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise e\n",
    "        response: str = cast(str, self.requests_wrapper.delete(data[\"url\"]))\n",
    "        response = response[: self.response_length]\n",
    "        return self.llm_chain.predict(\n",
    "            response=response, instructions=data[\"output_instructions\"]\n",
    "        ).strip()\n",
    "\n",
    "    async def _arun(self, text: str) -> str:\n",
    "        raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
